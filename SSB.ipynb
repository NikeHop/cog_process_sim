{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import numpy as np \n",
    "import torch\n",
    "import pyro.distributions\n",
    "import pyro.poutine as poutine\n",
    "import copy\n",
    "import time \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First abstract generative process from the perspective of an individual how performance results come into place\n",
    "### One construction principle must be that a variable muts not be known for it to work\n",
    "def abstractGP1(TI_mean_low,TI_mean_high,TI_var,TCadditive,TD_mean_low,TD_mean_high,TD_var,skill_mean,skill_var,luck_var,effort_var,p_low,p_high,group):\n",
    "    # TC: Task Choice, TC = 1 (Free choice) , always observed by the person\n",
    "    TC = pyro.sample('TC',pyro.distributions.Bernoulli(0.5)) \n",
    "    # TI: Task Importance, TI = 1 (High task importance), can be manipulated in the experiment\n",
    "    TI_discrete = pyro.sample('TI_discrete',pyro.distributions.Bernoulli(0.5))\n",
    "    TI_mean = TI_mean_high if TI_discrete else TI_mean_low\n",
    "    # Free choice increases the task importance by TCadditive\n",
    "    TI_mean = TI_mean + TCadditive * TC \n",
    "    # Sample task importance\n",
    "    TI = pyro.sample('TI',pyro.distributions.Normal(TI_mean,TI_var))  \n",
    "    # Sampling the skill level for the specific value\n",
    "    skill = pyro.sample('skill',pyro.distributions.Normal(skill_mean,skill_var))\n",
    "    # Sampling the effort level dependent on task importance \n",
    "    effort = pyro.sample('effort',pyro.distributions.Normal(TI,effort_var))\n",
    "    # Luck as random gaussian noise\n",
    "    luck = pyro.sample('luck', pyro.distributions.Normal(0,luck_var))  # maybe call it external, actualy specification can be different\n",
    "    # TD: Task difficulty, TD_discrete = 1 (High Task Difficulty), can be manipulated in the experiment\n",
    "    TD_discrete = pyro.sample('TD_discrete', pyro.distributions.Bernoulli(0.5))\n",
    "    TD_mean = TD_mean_high if TD_discrete else TD_mean_low\n",
    "    TD = pyro.sample('TD',pyro.distributions.Normal(TD_mean,TD_var))\n",
    "    \n",
    "    # Success prob is determined by \n",
    "    success_prob = p_low if (TD > (skill * effort + luck)) else p_high\n",
    "    outcome = pyro.sample('outcome',pyro.distributions.Bernoulli(success_prob))\n",
    "    \n",
    "    # At the moment self_concept, self_worth, image all represent the same concept\n",
    "    Self_concept = skill + effort \n",
    "    Self_worth = pyro.sample('self-worth',pyro.distributions.Normal(Self_concept,1))\n",
    "    Image = group * (skill + effort) \n",
    "    return (outcome.item(),Self_worth,Image.item()) # results are torch tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now for some settings we can sample and determine the outcome expectancy\n",
    "\n",
    "# Setting: \n",
    "TI_mean_low = 5\n",
    "TI_mean_high = 10\n",
    "TI_var = 2\n",
    "TD_mean_low = 5\n",
    "TD_mean_high = 30\n",
    "TD_var = 4\n",
    "TCadditive = 2  \n",
    "skill_mean = 5\n",
    "skill_var = 2\n",
    "luck_var = 2\n",
    "effort_var = 3 \n",
    "p_low = 0.01\n",
    "p_high = 0.99\n",
    "group = 0\n",
    "\n",
    "# What is a guideline to pick those variables: Prior to any observations we want certain outcome expectations ?\n",
    "# Maybe also dependent on variables such as self-esteem or self-concept.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The success prob is 0.83\n",
      "A good self-concept is on average: 15.579158782958984\n",
      "A negative self-concept is on average: 9.562623023986816\n"
     ]
    }
   ],
   "source": [
    "# Simulator: \n",
    "\n",
    "n = 100 # number of runs\n",
    "\n",
    "outcomes = []\n",
    "positive_self_concept = []\n",
    "negative_self_concept = []\n",
    "for _ in range(n):\n",
    "    results = abstractGP1(TI_mean_low,TI_mean_high,TI_var,TCadditive,TD_mean_low,TD_mean_high,TD_var,skill_mean,skill_var,luck_var,effort_var,p_low,p_high,group)\n",
    "    outcomes.append(results[0])\n",
    "    if results[0]:\n",
    "        positive_self_concept.append(results[1])\n",
    "    else:\n",
    "        negative_self_concept.append(results[1])\n",
    "    \n",
    "\n",
    "## Print out the outcome expectancy and results on self_concept. If outcome is failure the value is counted for negative self_concept etc.\n",
    "\n",
    "print('The success prob is {}'.format(sum(outcomes)/len(outcomes)))\n",
    "print('A good self-concept is on average: {}'.format(np.mean(np.array(positive_self_concept))))\n",
    "print('A negative self-concept is on average: {}'.format(np.mean(np.array(negative_self_concept))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now is the question: How do we use such a generative process: \n",
    "\n",
    "## As an example we take the teaching experiment\n",
    "## Each experimental condition is given by a certain set of observed values\n",
    "\n",
    "# Condition 1: No choice, high task importance, high task difficulty,failure: (Should show high SSB)\n",
    "data_cond1 = {'TC':torch.tensor(0,dtype=torch.float32),'TI_discrete':torch.tensor(1,dtype=torch.float32),'TD_discrete':torch.tensor(0,dtype=torch.float32),'outcome':torch.tensor(0,dtype=torch.float32),'self-worth':15}\n",
    "GP1_conditioned = pyro.condition(abstractGP1,data = data_cond1) # Condition the model: get back a callable\n",
    "\n",
    "# Now what do we do with this conditioned model. First lets try to do LWinference on the latent variables.\n",
    "\n",
    "\n",
    "\n",
    "## But how do we use this process for inference\n",
    "\n",
    "internal_var = [] # variables that are unobserved and would imply internal attribution style\n",
    "external_var = [] # variables that are unoberved and would imply external attribution style\n",
    "\n",
    "# Perform counterfactual inference: Changing an unknown variable does it effect the outcome \n",
    "# If yes this variable is seen as a cause if not it is not\n",
    "# Since we can only sample the outcome expectancy we need a cutoff value for the change to the conditioned model: \n",
    "\n",
    "\n",
    "# Perform hypthesis testing: Estimate the latent variables. \n",
    "# Question: How do we implement the biases ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Things to implement: \n",
    "# (1) In case the person has a negative self-esteem that we have a binary 0-1 variable that reduces the outcome expectancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np \n",
    "\n",
    "class LW():\n",
    "    \n",
    "    def __init__(self,model,observation,r = lambda x:x):\n",
    "    \n",
    "        '''\n",
    "        model - function/generative process containing primitives (stochastic/deterministic)\n",
    "        observation - dictionary with the variables observed - the observed values must be torch.tensors \n",
    "        r - function to apply to the latent variables (identity function)\n",
    "        *args are the model parameters \n",
    "        **kwargs are the model keyword parameters\n",
    "        '''\n",
    "        \n",
    "        self.model = model\n",
    "        self.observation = observation \n",
    "        self.r = r\n",
    "    \n",
    "    def inferLW(self,L,*args,**kwargs):\n",
    "        \n",
    "        '''\n",
    "        Input: L number of MC samples to get estimate\n",
    "        Output: return estimate of the latent variables \n",
    "        (Side comment: If we have estimates for the parameters of a parameterized distribution we have a posterior from which we can sample)\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        ### Condition the model on the observation \n",
    "        cond_model = pyro.condition(self.model,data = self.observation)\n",
    "        logWs = []\n",
    "        estimates = defaultdict(list)\n",
    "        for _ in range(L):\n",
    "            trace_DS = poutine.trace(cond_model).get_trace(*args,**kwargs)\n",
    "            trace_DS.log_prob_sum()\n",
    "            ### Get the observational nodes from the data structure\n",
    "            obs_nodes = trace_DS.observation_nodes\n",
    "            logWs.append(sum([trace_DS.nodes[elem]['log_prob_sum'] for elem in obs_nodes]))\n",
    "            ### Add the samples of the latent variables \n",
    "            __ = [estimates[elem].append(trace_DS.nodes[elem]['value']) for elem in trace_DS.stochastic_nodes]\n",
    "        ### Take the weighted average and apply r to the latent varibales \n",
    "        logWs = [np.exp(elem) for elem in logWs]\n",
    "        logW_sum= sum(logWs)\n",
    "        weights = np.array(logWs)/logW_sum.item() # can't divide by tensor\n",
    "        for key in estimates.keys():\n",
    "            estimates[key] = sum(self.r(np.array(estimates[key])) * weights)\n",
    "        return estimates, logW_sum  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'abstractGP1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-3bcc25c583b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mp_high\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel1_cond1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabstractGP1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_cond1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmodel1_cond1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferLW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTI_mean_low\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTI_mean_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTI_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTCadditive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTD_mean_low\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTD_mean_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTD_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskill_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskill_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mluck_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meffort_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_low\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_high\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'abstractGP1' is not defined"
     ]
    }
   ],
   "source": [
    "L = 10000\n",
    "TI_mean_low = 5\n",
    "TI_mean_high = 10\n",
    "TI_var = 2\n",
    "TD_mean_low = 5\n",
    "TD_mean_high = 30\n",
    "TD_var = 4\n",
    "TCadditive = 2  \n",
    "skill_mean = 5\n",
    "skill_var = 2\n",
    "luck_var = 2\n",
    "effort_var = 3 \n",
    "p_low = 0.01\n",
    "p_high = 0.99\n",
    "group = 0\n",
    "model1_cond1 = LW(abstractGP1,data_cond1)\n",
    "model1_cond1.inferLW(L,TI_mean_low,TI_mean_high,TI_var,TCadditive,TD_mean_low,TD_mean_high,TD_var,skill_mean,skill_var,luck_var,effort_var,p_low,p_high,group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concrete generative process - Experiment 1: Effect of Perceived Choice, expected outcome and actual outcome\n",
    "\n",
    "### They judged personal responsibility as a variable, but that should be inference right?\n",
    "### Wie krieg ich eine \n",
    "def concreteGP(TC_High_mean,TC_Low_mean,TC_var,skill_mean,skill_var,effort_var,luck_mean,luck_var,student_ability_mean,student_ability_var,PE_high_mean,PE_low_mean,PE_var,PO_var,Lower_Bound,Higher_Bound,self_worth_var,TC,PE):\n",
    "    # The parameters of the function give the condition of the experiment\n",
    "    # It would be nice if the abstract GP could take parameters such that we can adpot it to any experiment ? \n",
    "    # Rated \n",
    "    TC_mean = TC_High_mean if TC else TC_Low_mean\n",
    "    PerceivedTaskChoice = pyro.sample('PerceivedTC',pyro.distributions.Normal(TC_mean,TC_var))\n",
    "    skill = pyro.sample('skill_mean',pyro.distributions.Normal(skill_mean,skill_var)) \n",
    "    effort = pyro.sample('effort_mean',pyro.distributions.Normal(PerceivedTaskChoice,effort_var))\n",
    "    luck = pyro.sample('luck_mean',pyro.distributions.Normal(luck_mean,luck_var))\n",
    "    student_ability = pyro.sample('student_ability_mean',pyro.distributions.Normal(student_ability_mean,student_ability_var))\n",
    "    PE_mean = PE_high_mean if PE else PE_low_mean\n",
    "    PriorExperience = pyro.sample('PE_mean',pyro.distributions.Normal(PE_mean,PE_var))\n",
    "    # Prior Experience means what is my expectation that it works well \n",
    "    # On a scale from 1-9, 1 is a failure and 9 is success\n",
    "    summ = skill + effort + PriorExperience + luck + student_ability\n",
    "    absolute_sum = abs(skill) + abs(effort) + abs(luck) + abs(student_ability) + abs(PriorExperience)\n",
    "    PO_mean =  (summ/absolute_sum) * 10\n",
    "    if PO_mean < Lower_bound:\n",
    "        PO_mean = Lower_bound\n",
    "    if PO_mean > Higher_bound:\n",
    "        PO_mean = Higher_bound\n",
    "    PerceivedOutcome = pyro.sample('PerceivedOutcome',pyro.distributions.Normal(PO_mean,PO_var))\n",
    "    self_worth = pyro.sample('self-worth',pyro.distributions.Normal(skill + effort,self_worth_var))\n",
    "    return PerceivedOutcome,self_worth\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concreteGP() missing 17 required positional arguments: 'TC_var', 'skill_mean', 'skill_var', 'effort_var', 'luck_mean', 'luck_var', 'student_ability_mean', 'student_ability_var', 'PE_high_mean', 'PE_low_mean', 'PE_var', 'PO_var', 'Lower_Bound', 'Higher_Bound', 'self_worth_var', 'TC', and 'PE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-2a8c38d3b7ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcreteGP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected Outcome: {} '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: concreteGP() missing 17 required positional arguments: 'TC_var', 'skill_mean', 'skill_var', 'effort_var', 'luck_mean', 'luck_var', 'student_ability_mean', 'student_ability_var', 'PE_high_mean', 'PE_low_mean', 'PE_var', 'PO_var', 'Lower_Bound', 'Higher_Bound', 'self_worth_var', 'TC', and 'PE'"
     ]
    }
   ],
   "source": [
    "### Simulations to calibrate parameters: \n",
    "n = 100\n",
    "\n",
    "# the outcome variable of the generative process is the outcome\n",
    "TC = 0 \n",
    "PE = 0\n",
    "\n",
    "outcome = []\n",
    "\n",
    "for _ in range(n):\n",
    "    outcome.append(concreteGP(TC,PE))\n",
    "\n",
    "print('Expected Outcome: {} '.format(np.mean(np.array(outcome))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### What do we want to do: Sample some perceived outcome depending on what feedback the person received: Failure or success feedback\n",
    "### Try to find values for the external and internal variables that produce the perceived outcome \n",
    "### Value whether these variables are much different from the actual value if yes then we see it as a causal reason \n",
    "\n",
    "def expectation_based_inference_procedure(GP,internal,external,n,outcome,exp_param={},cond_param={},threshold=0,L=100):\n",
    "    '''\n",
    "    Param:\n",
    "    (0) GP (function): a function which describes the generative process\n",
    "    (1) internal (list): names of the variables that are internal\n",
    "    (2) external (list): names of the variables that are external\n",
    "    (3) exp_param: The GP should be parameterized such that the experiment is well described\n",
    "    (4) cond_param: parameters such that one experimental condition is satisified\n",
    "    (5) number of simulations to determine the expected outcome\n",
    "    (6) actual observed outcome\n",
    "    \n",
    "    Output: Which variables can be seen as the causal variables\n",
    "    '''\n",
    "    # Für jede Person wollen wir folgendes machen: Wir haben ein expected outcome mit unserem generativen prozess und auch ein selbstwert\n",
    "    # Wir haben ein wahrgenommenes outcome\n",
    "    # Wenn die Differenz zu groß ist fragen wir nach den Ursachen\n",
    "    # Dann konditionieren wir den Prozess auf das wahre outcome und den alten selbstwert (wollen wir erhalten)\n",
    "    # Bestimmen mit LW die means der neuen variablen\n",
    "    # Updaten den Prozess mit den neuen means\n",
    "    # Das Maß jetzt ist um wie viel ich die means updaten musste. Somit bekomme ich für jeder Person eine Kausalitätsscore\n",
    "    # Die kann ich dann in eine Skala von 1-9 umwandeln und mit den Resultaten vergleichen \n",
    "    # n ist dabei die Anzahl an Personen in einer Gruppe \n",
    "    \n",
    "    causality = []\n",
    "    count = 0\n",
    "    for _ in range(n):\n",
    "        print('{} %'.format(count/n))\n",
    "        count +=1\n",
    "        exp_outcome,self_worth = GP(*list(exp_param.values()),*list(cond_param.values()))\n",
    "        print('expected-outcome: {}'.format(exp_outcome))\n",
    "        actual_outcome = pyro.sample('actual_outcome',pyro.distributions.Normal(outcome,2))\n",
    "        print('actual_outcome: {}'.format(actual_outcome))\n",
    "        updated_model = LW(GP,{'PerceivedOutcome':actual_outcome,'self-worth':self_worth})\n",
    "        ### Inference on the update model with LW-inference\n",
    "        mean_values,log_p = updated_model.inferLW(L,*(list(exp_param.values()) + list(cond_param.values())))\n",
    "        ### Need to extract the mean values of the sampled parameters\n",
    "        internal_change = 0\n",
    "        external_change = 0\n",
    "        for key in mean_values.keys():\n",
    "            if key in set(internal.keys()):\n",
    "                internal_change += abs(mean_values[key]-exp_param[key])\n",
    "            if key in set(external.keys()):\n",
    "                external_change += abs(mean_values[key]-exp_param[key])\n",
    "        causality_ind = ((internal_change)/(internal_change + external_change)) * 8 + 1 # change to a score on 1-9\n",
    "        causality.append(causality_ind) \n",
    "    \n",
    "    print('The causality score is: {}'.format(np.mean(np.array(causality))))\n",
    "    return causality\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting the condition parameters and experimental parameters\n",
    "TC_High_mean = 7 \n",
    "TC_Low_mean = 3\n",
    "TC_var = 1.5\n",
    "skill_mean = 5\n",
    "skill_var = 2\n",
    "effort_var = 2\n",
    "luck_mean = 0\n",
    "luck_var = 2\n",
    "student_ability_mean = 0\n",
    "student_ability_var = 3\n",
    "PE_high_mean = 7\n",
    "PE_low_mean = 3\n",
    "PE_var = 1.5\n",
    "PO_var = 2\n",
    "Lower_Bound = 3\n",
    "Higher_Bound =7\n",
    "self_worth_var = 2\n",
    "expr_param = {'TC_High_mean':TC_High_mean,'TC_Low_mean':TC_Low_mean,'TC_var':TC_var,'skill_mean':skill_mean,'skill_var':skill_var,'effort_var':effort_var,'luck_mean':luck_mean,'luck_var':luck_var,'student_ability_mean':student_ability_mean,'student_ability_var':student_ability_var,'PE_high_mean':PE_high_mean,'PE_low_mean':PE_low_mean,'PE_var':PE_var,'PO_var':PO_var,'Lower_Bound':Lower_Bound,'Higher_Bound':Higher_Bound,'self_worth_var':self_worth_var}\n",
    "\n",
    "####\n",
    "TC = 0 # task choice\n",
    "PE = 0 # prior expectation negative\n",
    "## in these condition we should see a high outcome expectation\n",
    "cond_param = {'TC':TC,'PE':PE}\n",
    "### What do we set the variables of internal to ? \n",
    "internal = {'skill_mean': 9}\n",
    "external = {'luck_mean': -2, 'student_ability_mean':-2}\n",
    "n = 100\n",
    "outcome = 8\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Lower_bound' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-ea460b35ce84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Maybe its better to break the inference up in subprocedures:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcausality_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpectation_based_inference_procedure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcreteGP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minternal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexternal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpr_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcond_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-e4f68b31c659>\u001b[0m in \u001b[0;36mexpectation_based_inference_procedure\u001b[0;34m(GP, internal, external, n, outcome, exp_param, cond_param, threshold, L)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} %'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mexp_outcome\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself_worth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected-outcome: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_outcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mactual_outcome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'actual_outcome'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-89-4d32172c0fd5>\u001b[0m in \u001b[0;36mconcreteGP\u001b[0;34m(TC_High_mean, TC_Low_mean, TC_var, skill_mean, skill_var, effort_var, luck_mean, luck_var, student_ability_mean, student_ability_var, PE_high_mean, PE_low_mean, PE_var, PO_var, Lower_Bound, Higher_Bound, self_worth_var, TC, PE)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mabsolute_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskill\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meffort\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mluck\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_ability\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPriorExperience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mPO_mean\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0msumm\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabsolute_sum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mPO_mean\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mLower_bound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mPO_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLower_bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mPO_mean\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mHigher_bound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Lower_bound' is not defined"
     ]
    }
   ],
   "source": [
    "### Maybe its better to break the inference up in subprocedures: \n",
    "\n",
    "causality_scores = expectation_based_inference_procedure(concreteGP,internal,external,n,outcome,expr_param,cond_param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'causality_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-0506bb383f9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcausality_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'causality_scores' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(causality_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementing hypothesis testing as a human inference method \n",
    "\n",
    "def hypothesis_inference(model,hypothesis,fixed_param,dist_param,cond_param,n):\n",
    "    '''\n",
    "    hypothesis is a dictionary which contains for each random variable a proposed parameter value which represents\n",
    "    the hypothesis to be tested \n",
    "    '''\n",
    "    ranking = [] # contains tuples: the first element is the name of the hypothesis and the second is the self-worth value\n",
    "     \n",
    "    for key,value in hypothesis:\n",
    "        # Do inference on the model conditioned on the hypothesis\n",
    "        updated_model = LW(model, {key:value})\n",
    "        mean_values, log_P = updated_model.inferLW(L,*(list(exp_param.values()) + list(dist_param.values())+ list(cond_param.values())))\n",
    "        ### Get the self-worth value for the model after setting the new parameters \n",
    "        ## we need to copy the dictionary\n",
    "        updated_param = dist.copy()\n",
    "        for key in mean_values.keys():\n",
    "            updated_param[key] = mean_values[key]\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    for elem in ranking:\n",
    "        # test the hypothesis until one is confirmed\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':3,'b':4}\n",
    "b = a.copy()\n",
    "b['a']=5\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question is whether I can design my GP in such a way that it simplifies inference\n",
    "\n",
    "def concreteGP(TC_High_mean,TC_Low_mean,TC_var,skill_mean,skill_var,effort_var,luck_mean,luck_var,student_ability_mean,student_ability_var,PE_high_mean,PE_low_mean,PE_var,PO_var,Lower_Bound,Higher_Bound,self_worth_var,TC,PE):\n",
    "    # The parameters of the function give the condition of the experiment\n",
    "    # It would be nice if the abstract GP could take parameters such that we can adpot it to any experiment ? \n",
    "    # Rated \n",
    "    TC_mean = TC_High_mean if TC else TC_Low_mean\n",
    "    PerceivedTaskChoice = pyro.sample('PerceivedTC',pyro.distributions.Normal(TC_mean,TC_var))\n",
    "    skill = pyro.sample('skill_mean',pyro.distributions.Normal(skill_mean,skill_var)) \n",
    "    effort = pyro.sample('effort_mean',pyro.distributions.Normal(PerceivedTaskChoice,effort_var))\n",
    "    luck = pyro.sample('luck_mean',pyro.distributions.Normal(luck_mean,luck_var))\n",
    "    student_ability = pyro.sample('student_ability_mean',pyro.distributions.Normal(student_ability_mean,student_ability_var))\n",
    "    PE_mean = PE_high_mean if PE else PE_low_mean\n",
    "    PriorExperience = pyro.sample('PE_mean',pyro.distributions.Normal(PE_mean,PE_var))\n",
    "    # Prior Experience means what is my expectation that it works well \n",
    "    # On a scale from 1-9, 1 is a failure and 9 is success\n",
    "    summ = skill + effort + PriorExperience + luck + student_ability\n",
    "    absolute_sum = abs(skill) + abs(effort) + abs(luck) + abs(student_ability) + abs(PriorExperience)\n",
    "    PO_mean =  (summ/absolute_sum) * 10\n",
    "    if PO_mean < Lower_bound:\n",
    "        PO_mean = Lower_bound\n",
    "    if PO_mean > Higher_bound:\n",
    "        PO_mean = Higher_bound\n",
    "    PerceivedOutcome = pyro.sample('PerceivedOutcome',pyro.distributions.Normal(PO_mean,PO_var))\n",
    "    self_worth = pyro.sample('self-worth',pyro.distributions.Normal(skill + effort,self_worth_var))\n",
    "    return PerceivedOutcome,self_worth\n",
    "\n",
    "## 3 types of variables:\n",
    "# variables that indicate a condition -> should be categorical \n",
    "# variables that indicate determine a parameter\n",
    "# LW gibt mir für jedes sample statement einen wert -> ok aber dann sample ich nicht mehr sondern nehme den mittelwert\n",
    "# Wollen wir nicht umbedingt \n",
    "# Die einzigen Verteilungen die wir parameterisieren können, sind die die keine parent nodes haben \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human():\n",
    "    '''\n",
    "    Base class for individual participants of an experiment\n",
    "    Each participant is initialized with a generative process of the experiment which depends on the experimental settings \n",
    "    Each GP also has parameters of the experiment which can be tuned to produce numerical results close to the ones found in the experiment \n",
    "    Example given: In the experiment humans should rate for how important they consider the task on a 1-9 scale\n",
    "    Then we have a param task_importance_mean, task_importance_var \n",
    "    These can then be tuned to the data after the experiment\n",
    "    Assume we model it with a normal probability: We\n",
    "    In case this is an experimental condition which was manipulated we should have \n",
    "    task_importance_mean_lower, task_importance_var_lower\n",
    "    task_importance_mean_high, task_importance_var_high\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,GP,process_param,personality = [], situation = [],n = 1, obs = []):\n",
    "        self.IT = GP\n",
    "        self.personality = personality  # a list of all personal variables\n",
    "        self.situation = situation # list of all the situational variables \n",
    "        self.process_param = process_param # list of the process parameters, need to be calibrated on the data\n",
    "        self.n = n # number of participants of this type\n",
    "        self.obs = obs # outcome observations for the participants\n",
    "        \n",
    "    def add_situation(new_aspect):\n",
    "        assert isinstance(new_aspect,characteristic)\n",
    "        self.situation.append(new_aspect)\n",
    "        \n",
    "    def add_personality(new_trait):\n",
    "        assert isinstance(new_aspect,characteristic)\n",
    "        self.situation.append(new_trait)\n",
    "    \n",
    "    def get_expectation(self):\n",
    "        return self.IT(*self.personality,*self.situation,*self.process_param)\n",
    "    \n",
    "        \n",
    "    def callibrate(data):\n",
    "        pass\n",
    "        \n",
    "    def self_worth_protection_inference(self,L):\n",
    "        '''\n",
    "        Implement the self_worth_protection inference method with the new way of writing GP\n",
    "        '''\n",
    "        personal_causality = []\n",
    "\n",
    "        for i in tqdm(range(self.n)):\n",
    "            exp_outcome,self_worth = self.IT(*self.personality,*self.situation,*self.process_param)\n",
    "            actual_outcome = self.obs[i]\n",
    "            data = {'Expected Outcome':actual_outcome,'Self-Worth':self_worth}\n",
    "            updated_model = LW(self.IT,data)\n",
    "            ### Inference on the update model with LW-inference\n",
    "            mean_values,log_p = updated_model.inferLW(L,*self.personality,*self.situation,*self.process_param)\n",
    "            ### Need to extract the mean values of the sampled parameters\n",
    "            internal_change = 0\n",
    "            external_change = 0\n",
    "            external_count = 0\n",
    "            internal_count = 0\n",
    "            for elem in self.personality:\n",
    "                if elem.name not in data.keys():\n",
    "                    internal_count += 1\n",
    "                    internal_change += abs(mean_values[elem.name]-elem.get_param()[0])\n",
    "            for elem in self.situation:\n",
    "                if elem.name not in data.keys():\n",
    "                    external_count += 1\n",
    "                    external_change += abs(mean_values[elem.name]-elem.get_param()[0])\n",
    "            external_change *= internal_count/external_count\n",
    "            internal_change *= external_count/internal_count\n",
    "            causality_ind = ((internal_change)/(internal_change + external_change)) * 8 + 1 # change to a score on 1-9\n",
    "            personal_causality.append(causality_ind) \n",
    "        return personal_causality\n",
    "\n",
    "    \n",
    "    def hypothesis_testing_inference(self,L):\n",
    "        '''\n",
    "        General idea: each hypothesis is given by observing a certain value\n",
    "        Under each hypothesis we have a certain self-worth \n",
    "        We rank all hypothesis regarding their self-worth \n",
    "        Then we test the hypothesis. How tough the test is depends on the self-worth\n",
    "        High self-worth gives easy testing and vice versa \n",
    "        Easy testing means the hypothesis is accepted \n",
    "        As soon as we have accepted an hypothesis we stop the process and have the causal reason \n",
    "        Question now is how to generate these hypothesis - especially the parameter values  \n",
    "        '''\n",
    "        \n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In what way do we implement GP \n",
    "### In psychology we try to measure ein Merkmal \n",
    "### ein Merkmal wird gemessen auf einer Skala \n",
    "### Wir müssen eine Verteilung annehmen (später vielleicht empirische Verteilung)\n",
    "### ist es external(situation) oder internal(position)\n",
    "\n",
    "class characteristic():\n",
    "    '''\n",
    "    Base class for characteristics \n",
    "    '''\n",
    "    # class attribute: Dict of distributions which possibly represent the parameter\n",
    "    distributions = {'Normal':pyro.distributions.Normal,'Bernoulli': pyro.distributions.Bernoulli,'Binomial':pyro.distributions.Binomial}\n",
    "    \n",
    "                     \n",
    "    def __init__(self,name,scale,type_dist,type_characteristic,param = None):\n",
    "        self.name = name \n",
    "        self.scale = scale # scale of the method which records the characteristic\n",
    "        self.type_dist = type_dist # string such as 'Normal' \n",
    "        self.type_characteristic = 1 if type_characteristic=='internal' else 0 # type: internal (=1) or external (=0)\n",
    "        self.param = param\n",
    "    def init_dist(self):\n",
    "        return self.distributions[self.type_dist](*self.param)\n",
    "    \n",
    "    def set_param(self,param):\n",
    "        self.param = param # a list containing the parameters that describe the distirbution\n",
    "    \n",
    "    def get_param(self):\n",
    "        return self.param\n",
    "        \n",
    "    \n",
    "\n",
    "### What are good ways to represent scales -> maybe another class: domain knowledge needed what are typical scales \n",
    "\n",
    "class scale(object):\n",
    "    \n",
    "    def __init__(self,name,minn,maxx,bool_cont):\n",
    "        self.name = name\n",
    "        self.minn = minn\n",
    "        self.maxx = maxx\n",
    "        self.bool_cont = bool_cont\n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing out the characteristic class \n",
    "### Problem: What to do with latent states for which we do not measure it on any scale ??\n",
    "Likert1_9 = scale('Likert: 1-9',1,9,True)\n",
    "Likert1_18 = scale('Likert: 1-18',1,18,True)\n",
    "\n",
    "\n",
    "TI = characteristic('task importance',Likert1_9,'Normal','external')\n",
    "mean = 2\n",
    "var = 1\n",
    "TI.set_param([mean,var])\n",
    "Skill = characteristic('Skill',Likert1_9,'Normal','internal')\n",
    "mean = 5 \n",
    "var = 2\n",
    "Skill.set_param([mean,var])\n",
    "Effort = characteristic('Effort',Likert1_9,'Normal','internal')\n",
    "mean = 5 \n",
    "var = 2\n",
    "Effort.set_param([mean,var])\n",
    "### If two characteristics are added up, multiplied: try to combine their scales \n",
    "Self_Worth = characteristic('Self-Worth',Likert1_18,'Normal','internal')\n",
    "Student_Ability = characteristic('Student Ability',Likert1_9,'Normal','external')\n",
    "mean = 5\n",
    "var = 2\n",
    "Student_Ability.set_param([mean,var])\n",
    "Prior_Experience = characteristic('Prior Experience',Likert1_9,'Normal','external')\n",
    "mean = 5\n",
    "var = 2\n",
    "Prior_Experience.set_param([mean,var])\n",
    "Expected_Outcome = characteristic('Expected Outcome',Likert1_9,'Normal','internal')\n",
    "Expected_Outcome.set_param([0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing a GP with the characteristics classes \n",
    "\n",
    "def GP_versuch(Skill,Effort,Self_Worth,Prior_Experience,Student_Ability,TI,c_1,c_2):\n",
    "    ti = pyro.sample(TI.name,TI.init_dist())\n",
    "    skill = pyro.sample(Skill.name,Skill.init_dist()) #1-9 scale\n",
    "    effort = pyro.sample(Effort.name,Effort.init_dist()) #1-9 scale\n",
    "    prior_experience = pyro.sample(Prior_Experience.name,Prior_Experience.init_dist()) #1-9 scale\n",
    "    student_ability = pyro.sample(Student_Ability.name,Student_Ability.init_dist()) #1-9 scale\n",
    "    ## Determine Self-Worth \n",
    "    var = Skill.get_param()[1] + Effort.get_param()[1]\n",
    "    Self_Worth.set_param([skill + effort, var])\n",
    "    self_worth = pyro.sample(Self_Worth.name,Self_Worth.init_dist())\n",
    "    self_worth = c_1 * ti\n",
    "    ## Determine Expected Outcome\n",
    "    outcome_mean = skill + effort + prior_experience - c2*student_ability\n",
    "    Expected_Outcome.set_param([outcome_mean,Expected_Outcome.get_param()[1]])\n",
    "    expected_outcome = pyro.sample(Expected_Outcome.name, Expected_Outcome.init_dist())\n",
    "    return expected_outcome, self_worth\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.04938719231671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "c1,c2 = 1,1\n",
    "traits = [Skill,Effort,Self_Worth,Prior_Experience]\n",
    "student_ability = [Student_Ability,TI]\n",
    "### Observationen erzeugen \n",
    "mean = 2\n",
    "var = 2\n",
    "N = 100 \n",
    "obs = []\n",
    "for elem in range(N):\n",
    "    obs.append(pyro.distributions.Normal(mean,var).rsample())\n",
    "    \n",
    "participant1 = Human(GP_versuch,process_param = [c1,c2],personality = traits ,situation = student_ability,n = N,obs = obs )\n",
    "participant1.get_expectation()\n",
    "L = 100\n",
    "personal_causality = participant1.self_worth_protection_inference(L)\n",
    "print(np.mean(np.array(personal_causality)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2476)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.distributions.Normal(mean,var).rsample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Writing a GP for the new experiment \n",
    "### Extending the Human class with a new inference method \n",
    "\n",
    "### Since the actual scale does not matter for each trait we sample from a normal distribution centered around 0 \n",
    "mu = 5 \n",
    "sigma = 2 \n",
    "normal_scale = scale('normal_support',-np.inf,np.inf,True)\n",
    "Skill = characteristic('Skill','Normal')\n",
    "Skill.set_param([mu,sigma])\n",
    "External \n",
    "\n",
    "### Two new moderators: Improvement Possibilities, Self-awareness\n",
    "\n",
    "def GP_versuch(Skill,Effort,Self_Worth,Prior_Experience,TI,c_1,c_2):\n",
    "    skill = pyro.sample(Skill.name,Skill.init_dist()) \n",
    "    effort = pyro.sample(Effort.name,Effort.init_dist())\n",
    "    \n",
    "    var = Skill.get_param()[1] + Effort.get_param()[1]\n",
    "    Self_Worth.set_param([skill + effort, var])\n",
    "    self_worth = pyro.sample(Self_Worth.name,Self_Worth.init_dist())\n",
    "    self_worth = c_1 * ti\n",
    "    ## Determine Expected Outcome\n",
    "    outcome_mean = skill + effort + prior_experience - TD\n",
    "    Expected_Outcome.set_param([outcome_mean,Expected_Outcome.get_param()[1]])\n",
    "    expected_outcome = pyro.sample(Expected_Outcome.name, Expected_Outcome.init_dist())\n",
    "    return expected_outcome, self_worth\n",
    "\n",
    "### How could we implement the inference method -> two competeing methods \n",
    "### Compare it to a self image -> compare parameters to a self image -> measure negative effect\n",
    "### Normal inference system is given by just by conditioning on expected_outcome nothing else\n",
    "### Comparing to self-image only if self-awarenss is high -> otherwise normal inference \n",
    "### Possibility of improvement: We need a measure how chagneable the traits are ? \n",
    "### If it is changeable\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
